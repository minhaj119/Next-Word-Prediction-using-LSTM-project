# Next-Word-Prediction-using-LSTM-project
Developed an LSTM-based text generation model that predicts the next word in a sentence using sequence modeling techniques. Implemented preprocessing, tokenization, and model training using TensorFlow and Keras.
# Next Word Prediction using LSTM

This project demonstrates how to build a **Next Word Prediction Model** using an **LSTM neural network** in Python. It learns from text sequences and predicts the most likely next word in a sentence.

## Objective
To understand the concept of sequence modeling and apply deep learning (LSTM) to natural language processing (NLP) tasks.

## Key Features
- Tokenization of input text
- Sequence padding
- LSTM-based deep learning model
- Text generation with trained model

## Tools & Technologies
- Python
- TensorFlow / Keras
- NumPy
- NLP
- Google Colab / Jupyter Notebook

## Steps Performed
1. Prepared and tokenized text data.
2. Created sequences for training the model.
3. Built and trained an LSTM neural network.
4. Implemented next-word prediction using trained weights.

## Example Output
Input: `machine learning`  
Predicted Sequence: `machine learning helps computers`

## Files
- `next_word_prediction.ipynb` â€” full training and prediction notebook.

## Author
**Mohammed Minhaj Begum**  
Aspiring Data Analyst | Python Developer | AI/ML Enthusiast
